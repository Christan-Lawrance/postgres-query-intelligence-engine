# Architecture â€” Postgres Query Intelligence Engine

This document explains **how the system is structured, why it is structured this way, and how data flows end to end**.

The goal of this architecture is **correctness, observability, and explainability**, not speed of implementation.

---

## ðŸ§­ Phase-by-Phase System Flow

The system is intentionally built in phases, each adding **one responsibility**.

### Phase 0 â€” Repository & Discipline

* Git-first workflow
* Clean commit history
* No code without intent

This ensures the project grows **deliberately**, not accidentally.

---

### Phase 1 â€” Architecture & Thinking

* Problem boundaries defined
* Responsibilities separated
* No database or framework decisions made prematurely

This phase prevents overfitting to tools instead of the problem.

---

### Phase 2 â€” Data Model Design

Core entities:

* `queries`
* `query_executions`
* `query_analysis`
* `recommendations`

The data model is designed **before writing SQLAlchemy models**.

This avoids ORM-driven schema mistakes.

---

### Phase 2.5 â€” ORM Models

* SQLAlchemy models mirror schema
* No business logic inside models
* Relationships used sparingly

Models act as **contracts**, not helpers.

---

### Phase 3 â€” Alembic & Schema Reality

* Alembic initialized once
* Migrations written manually
* Indexes created intentionally

At this phase, the schema becomes **real**, not theoretical.

---

### Phase 4 â€” SQLAlchemy Instrumentation

* Engine event hooks capture query execution
* Execution timing measured precisely
* Queries normalized
* Metrics persisted automatically

Instrumentation is **transparent** to application code.

---

### Phase 5 â€” Query Analysis Engine

* Slow-query policy defined
* Execution metrics aggregated
* EXPLAIN ANALYZE run conditionally
* Execution plans stored as JSON

The system begins to **reason**, not just record.

---

### Phase 6 â€” GraphQL API

* Read-only observability API
* Batched data fetching
* No N+1 queries

GraphQL acts as a **window**, not a processing layer.

---

### Phase 7 â€” LLM Insight Engine

* LLM invoked only after analysis
* Structured JSON output enforced
* Confidence score generated by LLM
* System validates and guards confidence

LLM adds **interpretation**, not authority.

---

### Phase 8 â€” Production Hardening

* Reliability guards
* Logging
* Demo scripts
* Documentation

The system is now **hand-off ready**.

---

## ðŸ§© Why Queries, Executions, and Analysis Are Separate

### `queries`

Represents the **identity** of a query.

* Normalized SQL
* Independent of individual runs
* Aggregation anchor

This avoids treating every literal variation as a new query.

---

### `query_executions`

Represents **events over time**.

* Execution timestamp
* Duration
* Row counts

This table is time-series data and grows fast.

Separating it enables:

* Historical analysis
* Percentiles
* Trend detection

---

### `query_analysis`

Represents **interpretation of behavior**.

* EXPLAIN plans
* Scan detection
* Derived metrics

Analysis is expensive and conditional â€” it should not run on every execution.

---

### Why this separation matters

Mixing these concerns would:

* Destroy aggregation ability
* Inflate storage
* Obscure reasoning

The separation mirrors how real observability systems work.

---

## ðŸ§± Why Alembic Migrations Are Manual

Auto-generated migrations:

* Hide intent
* Miss indexes
* Break in production

Manual migrations ensure:

* Explicit constraints
* Correct downgrade paths
* Schema decisions are reviewed

The database schema is treated as **source code**, not output.

---


## Why GraphQL

GraphQL is chosen not for trendiness, but for alignment with the problem domain.

Query analysis is inherently exploratory: users may want classifications, plan details, detected issues, explanations, or summaries â€” often in different combinations. GraphQL allows clients to request *exactly* the depth and shape of analysis they need without over-fetching or rigid endpoint design.

More importantly, GraphQLâ€™s strongly typed schema acts as living documentation for the systemâ€™s reasoning model. It forces clarity around what the system knows, what it infers, and what it explains. As the engine evolves, GraphQL enables additive growth without breaking existing consumers.

In short: GraphQL matches the systemâ€™s need for introspection, flexibility, and explicit structure.

---

## âš¡ Why GraphQL Uses Batched Loading

Naive GraphQL field resolvers cause:

* N+1 queries
* Unpredictable performance

This system:

* Fetches all required data in batches
* Groups in memory
* Assembles responses deterministically

Performance characteristics are **constant**, not input-dependent.

---

## ðŸ¤– Why LLM Confidence Is Guarded

LLMs:

* Are persuasive
* Are inconsistent
* Lack system-wide context

Therefore:

* LLM proposes a confidence score
* System validates and clamps it
* Confidence can only be reduced, not inflated

Confidence represents **evidence strength**, not certainty.

The system owns the final truth.

---

## ðŸ”‘ Core Architectural Principles

* Explicit over implicit
* Data integrity over convenience
* Determinism over magic
* Observability before optimization
* AI as advisor, not authority

---

## ðŸ§  Final Thought

This architecture is designed so that:

* Every decision is explainable
* Every failure mode is safe
* Every layer can be reasoned about independently

This is how internal platform systems are actually built.
